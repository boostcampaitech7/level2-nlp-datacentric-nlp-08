{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM 도메인 예측\n",
    "### 타겟별 Noisy dataset을 예시로 넣고, 주제를 예측하라고 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "from langchain_core.prompts.few_shot import FewShotPromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_589628/3434335749.py:2: LangChainDeprecationWarning: The class `Ollama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaLLM``.\n",
      "  llm = Ollama(model=\"gemma2\")\n"
     ]
    }
   ],
   "source": [
    "# 사용할 LLM 모델 설정\n",
    "llm = Ollama(model=\"gemma2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "import json\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# JSON 출력 파서 초기화\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 프롬프트 템플릿 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \n",
    "     '''당신은 손상된 기사 제목들을 종합적으로 분석하여 전체 기사들의 공통된 도메인을 예측하는 어시스턴트입니다.\n",
    "     주어지는 모든 기사 제목들을 함께 고려하여, 이 기사들이 속한 하나의 도메인을 판단하세요.\n",
    "     도메인은 한국어이며, 한 단어로 표현해주세요.\n",
    "     모든 기사 제목들에서 발견되는 주요 키워드들을 추출하세요.\n",
    "     \n",
    "     도메인 예시:\n",
    "     - 정치\n",
    "     - 북한\n",
    "     - 경제\n",
    "     - 산업\n",
    "     - 사회\n",
    "     - 전국\n",
    "     - 세계\n",
    "     - 문화\n",
    "     - 건강\n",
    "     - 연예\n",
    "     - 스포츠\n",
    "     \n",
    "     다음 정보를 제공하세요:\n",
    "     1. 모든 기사들에서 추출된 주요 키워드들을 하나의 리스트로\n",
    "     2. 기사들의 공통된 도메인\n",
    "     3. 도메인 예측 근거\n",
    "     '''),\n",
    "    (\"human\", \n",
    "     '''다음 기사 제목들을 분석하여 하나의 도메인으로 분류해주세요:\n",
    "     \n",
    "     기사들: {examples}\n",
    "     \n",
    "     {format_instructions}\n",
    "     ''')\n",
    "])\n",
    "\n",
    "def create_unified_domain_classifier(llm):\n",
    "    \"\"\"통합 도메인 분류기 체인 생성\"\"\"\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    def classify_domain(examples: List[str]) -> Dict:\n",
    "        \"\"\"여러 기사 제목들을 하나의 도메인으로 분류\"\"\"\n",
    "        response = chain.invoke({\n",
    "            \"examples\": \"\\n\".join(examples),\n",
    "            \"format_instructions\": \"\"\"출력은 다음 JSON 형식이어야 합니다:\n",
    "            {\n",
    "                \"keywords\": [\"키워드1\", \"키워드2\", ...],\n",
    "                \"domain\": \"예측된_도메인\",\n",
    "                \"reasoning\": \"도메인 예측 근거\"\n",
    "            }\"\"\"\n",
    "        })\n",
    "        return response\n",
    "    \n",
    "    return classify_domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"주요 키워드\": [\n",
      "    \"김정은\",\n",
      "    \"문재인\",\n",
      "    \"북한\",\n",
      "    \"반도\",\n",
      "    \"대통령\",\n",
      "    \"경제\",\n",
      "    \"사회\",\n",
      "    \"핵무기\",\n",
      "    \"미국\",\n",
      "    \"전쟁\",\n",
      "    \"의원\",\n",
      "    \"정치\"\n",
      "  ],\n",
      "  \"공통된 도메인\": \"정치\",\n",
      "  \"도메인 예측 근거\": \"제목에서 김정은, 문재인, 북한, 대통령 등 정치적 인물과 주제가 자주 등장하며, 경제, 사회, 핵무기 등 관련된 문제들 또한 언급되어 있습니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "examples = [\n",
    "    \"m 김정) 자주통일 새,?r열1나가야1보\",\n",
    "    \"靑$김기식 논j:정면돌파 태세9선관위 '권해석 결과가 A수\",\n",
    "    \"-용9 與 최고위원 출마…난 親~민계 당 위해 Kz\",\n",
    "    \"지방서 새누-당 ,q 동v 촉구 이어져d일부는 7참 X대\",\n",
    "    \"朴대통' 한 北비핵N 우선1칙따라 공조강화해야종1\",\n",
    "    \"I기 나누는 1종석 비서실장과*한병i 정무T석\",\n",
    "    \"文대통령n청년일자? 0술방망이 없ae하나씩 만들어가E\",\n",
    "    \"되돌아본 한0 정-이A2C대 총~ 선거구 가J스로 지각:정\",\n",
    "    \"유U 北제재 북한 5월 당대회서 경제`과V과시 [건xU가나\",\n",
    "    \"단Z 朴 뇌2> 핵심B퍼즐 나왔다…i성에 최순실 5원-요구\",\n",
    "    \"환영사$하는 문 대x령\",\n",
    "    \"국정원장q*병우 직보 ?혹 국장,감찰 조사$중속보\",\n",
    "    \"與텃밭/부산 Z변0더G주 4곳이{ 앞서\",\n",
    "    \"[ '대통령재벌 총수 u공& 면담 경위 수사종b\",\n",
    "    \"北0대! 김정*2향한 성경쟁 무대된l릴레이r토론\"\n",
    "]\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"keywords\": [\n",
      "    \"학교\",\n",
      "    \"교육청\",\n",
      "    \"부산\",\n",
      "    \"경북\",\n",
      "    \"학생\",\n",
      "    \"공무직\",\n",
      "    \"단식\",\n",
      "    \"동\",\n",
      "    \"사회서비스\",\n",
      "    \"지역\",\n",
      "    \"주택\",\n",
      "    \"금융\",\n",
      "    \"기업\",\n",
      "    \"임원\",\n",
      "    \"법\",\n",
      "    \"경제\",\n",
      "    \"국립전통예술고등학교\",\n",
      "    \"유학\",\n",
      "    \"민간추진협의회\",\n",
      "    \"출식\",\n",
      "    \"보도\",\n",
      "    \"방송편자협회\",\n",
      "    \"토론회\",\n",
      "    \"사칭\",\n",
      "    \"대학\",\n",
      "    \"학원\",\n",
      "    \"임금\",\n",
      "    \"학교폭력\",\n",
      "    \"청소년\",\n",
      "    \"건강\",\n",
      "    \"국가기관\",\n",
      "    \"시정\",\n",
      "    \"일제\",\n",
      "    \"고용\",\n",
      "    \"사회\",\n",
      "    \"문화\"\n",
      "  ],\n",
      "  \"domain\": \"사회\",\n",
      "  \"reason\": \"주요 키워드 분석 결과, 학교, 교육청, 부산, 경북 등 지역 사회 관련 용어와 공무직, 단식, 사회서비스, 지역 주택, 금융 기업 등 사회 문제와 연결된 키워드가 많이 발견됩니다. 또한 청소년, 건강, 국가기관과 같은 키워드도 포함되어 사회 전체에 대한 다양한 측면을 담고 있는 것으로 판단되었습니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "examples = [\n",
    "    \"땅 파= 코l나 격리시설 탈출한 외국인 청_서 VS\",\n",
    "    \"모멘트 학교 급식U4칸막이lx곡\",\n",
    "    \"초등학생들 경북도청 |들`\",\n",
    "    \"한9%^6주택브랜드 공작소 론칭\",\n",
    "    \"김영란법 때문에E애플 t이폰 초청70못받7 r국 언.\",\n",
    "    \"부7교육청 D식종&자 등 7개 0. 육공무직 19}o 8발\",\n",
    "    \"3주 사회서비스F 1급 사무/장 등 u부 직원 q명 공q\",\n",
    "    \"코리아^레길 민간추진협의회 2<일 출u식\",\n",
    "    \")보통신산업진흥원 ~#7후보 3.수 압축\",\n",
    "    \"0용 공고 보는XK직자들\",\n",
    "    \"영상 -랑V 유학 포기할까요…한국 유학9G &6금 n상에 충격\",\n",
    "    \"신#계A선호텔 국립전통예술고f*생에3장학금 R원\",\n",
    "    \",시y 9z방송편}인협회5김동연 부총리 초청 토론회\",\n",
    "    \"금감원 이어 공정위까지…6부기관[사칭B악h메1 기승\",\n",
    "    \"확진 속출F부산 사하구B모든 학교 이틀간 RV수업3q7교 대3\",\n",
    "    \"충북.e7D년제 대학 @록금 H21만원…전국 평균 웃돌아\",\n",
    "    \"黃 단식중단w도 패스트$랙|대치 @속…靑감찰의혹 공L 가열\",\n",
    "    \"9살 학대 )동 4층P베란다 난간to3 넘어 목숨 건9맨발 _출\",\n",
    "    \"오q지라이프{임원들 6사주y매각;보도는 사실무b\",\n",
    "    \"항소심2선고 출석하는 이%택\"\n",
    "]\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특수문자 비율의 threshold를 0.2로 했을 때의 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Count     Ratio\n",
      "target                 \n",
      "3          24  0.214286\n",
      "6          20  0.178571\n",
      "5          19  0.169643\n",
      "0          15  0.133929\n",
      "2          15  0.133929\n",
      "1          13  0.116071\n",
      "4           6  0.053571\n"
     ]
    }
   ],
   "source": [
    "noisy_df = pd.read_csv('basic_noisy.csv')\n",
    "noisy_df = noisy_df.drop(columns=['Unnamed: 0', 'target_name', 're_text'])\n",
    "\n",
    "# 각 target별 개수와 비율 구하기\n",
    "target_counts = noisy_df['target'].value_counts()\n",
    "target_ratios = noisy_df['target'].value_counts(normalize=True)\n",
    "\n",
    "# 결과 출력\n",
    "result_df = pd.DataFrame({\n",
    "    'Count': target_counts,\n",
    "    'Ratio': target_ratios\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = noisy_df[noisy_df['target']==0]\n",
    "list_0 = df_0['text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"keywords\": [\n",
      "    \"화천\",\n",
      "    \"눈썰매\",\n",
      "    \"축제\",\n",
      "    \"연극\",\n",
      "    \"산\",\n",
      "    \"호우\",\n",
      "    \"경보\",\n",
      "    \"목전\",\n",
      "    \"롯데백화점\",\n",
      "    \"예지\",\n",
      "    \"독립 선언문\"\n",
      "  ],\n",
      "  \"domain\": \"문화\",\n",
      "  \"reason\": \"제공된 기사 제목들을 분석해 보면 축제, 연극, 산과 관련된 내용이 눈에 띄며, 예지와 독립선언문 등 문화적 사건에 대한 기사도 포함되어 있습니다. 따라서 이러한 키워드들의 공통점으로 '문화' 도메인으로 분류했습니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "examples = list_0\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"keywords\": [\n",
      "    \"농구\",\n",
      "    \"야구\",\n",
      "    \"축구\",\n",
      "    \"프로야구\",\n",
      "    \"대표팀\",\n",
      "    \"한국\",\n",
      "    \"개막\",\n",
      "    \"선수\",\n",
      "    \"경기\",\n",
      "    \"승리\",\n",
      "    \"시즌\"\n",
      "  ],\n",
      "  \"domain\": \"스포츠\",\n",
      "  \"reason\": \"제공된 기사 제목들은 대부분 농구, 야구, 축구 등 다양한 스포츠 분야의 경기 개막, 선수, 시합 결과 등을 다루고 있습니다. 따라서 이들 기사들의 공통적인 주제는 '스포츠'입니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "df_1 = noisy_df[noisy_df['target']==1]\n",
    "list_1 = df_1['text'].to_list()\n",
    "examples = list_1\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"keywords\": [\n",
      "    \"김기식\",\n",
      "    \"청년\",\n",
      "    \"문재인\",\n",
      "    \"朴대통령\",\n",
      "    \"북한\",\n",
      "    \"최순실\",\n",
      "    \"지방선거\",\n",
      "    \"국정원\",\n",
      "    \"경제\",\n",
      "    \"핵심\",\n",
      "    \"의외\",\n",
      "    \"변동\",\n",
      "    \"고위원\",\n",
      "    \"수사\",\n",
      "    \"토론\"\n",
      "  ],\n",
      "  \"domain\": \"정치\",\n",
      "  \"reason\": \"기사 제목에서 다양한 정치적 키워드가 나타납니다. 대표적으로 '김기식 논란', '朴대통령', '문재인', '지방선거', '북한', '최순실', '국정원' 등이 언급되어 있습니다. 또한, '수사', '토론', '의외', '변동' 등의 키워드는 정치 현상에 대한 분석과 논의를 나타냅니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "df_2 = noisy_df[noisy_df['target']==2]\n",
    "list_2 = df_2['text'].to_list()\n",
    "examples = list_2\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"keywords\": [\n",
      "    \"학교\",\n",
      "    \"청소년\",\n",
      "    \"주택\",\n",
      "    \"교육\",\n",
      "    \"정부\",\n",
      "    \"여행\",\n",
      "    \"사회\",\n",
      "    \"금융\",\n",
      "    \"사업\",\n",
      "    \"뉴스\",\n",
      "    \"인구\",\n",
      "    \"학생\",\n",
      "    \"경제\",\n",
      "    \"법률\",\n",
      "    \"오보\",\n",
      "    \"동네\",\n",
      "    \"공무원\"\n",
      "  ],\n",
      "  \"domain\": \"사회\",\n",
      "  \"reason\": \"기사 제목에서 다양한 사회 현상에 대한 뉴스와 정보를 확인할 수 있습니다. 학교, 교육, 정부 정책, 경제, 법률, 사회 문제 등이 포함되어 있어 사회 분야를 대표하는 도메인으로 판단됩니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "df_3 = noisy_df[noisy_df['target']==3]\n",
    "list_3 = df_3['text'].to_list()\n",
    "examples = list_3\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"keywords\": [\n",
      "    \"기업\",\n",
      "    \"경제\",\n",
      "    \"중소기업\",\n",
      "    \"조합\",\n",
      "    \"공동주택\",\n",
      "    \"건설\",\n",
      "    \"인건비\",\n",
      "    \"증시\",\n",
      "    \"가격지수\",\n",
      "    \"해운\",\n",
      "    \"금융\",\n",
      "    \"자산\",\n",
      "    \"생산\",\n",
      "    \"제조업\",\n",
      "    \"합병\",\n",
      "    \"선임\",\n",
      "    \"기본계약\",\n",
      "    \"취득\",\n",
      "    \"도시\",\n",
      "    \"부동산\",\n",
      "    \"출국금지\",\n",
      "    \"브랜드\"\n",
      "  ],\n",
      "  \"domain\": \"경제\",\n",
      "  \"reason\": \"제공된 기사 제목에서 '중소기업', '증시', '가격지수', '인건비', '합병', '생산', '금융', '부동산' 등 경제 분야와 직접적인 관련이 있는 키워드들이 주로 나타납니다. 또한, '해운', '경기', '중국'과 같은 주요 산업의 상황을 보여주는 단어들도 포함되어 있어 경제 전체를 다루고 있음을 시사합니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "df_5 = noisy_df[noisy_df['target']==5]\n",
    "list_5 = df_5['text'].to_list()\n",
    "examples = list_5\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"주요 키워드\": [\n",
      "    \"중국\",\n",
      "    \"일본\",\n",
      "    \"북한\",\n",
      "    \"프랑스\",\n",
      "    \"미국\",\n",
      "    \"아랍\",\n",
      "    \"수단\",\n",
      "    \"터키\",\n",
      "    \"필리핀\",\n",
      "    \"영국\",\n",
      "    \"유엔\",\n",
      "    \"브렉시트\",\n",
      "    \"시위\",\n",
      "    \"군부\",\n",
      "    \"정치\",\n",
      "    \"외교\",\n",
      "    \"핵\",\n",
      "    \"폭발\",\n",
      "    \"사망\",\n",
      "    \"전쟁\",\n",
      "    \"경제\",\n",
      "    \"투자\",\n",
      "    \"스포츠\",\n",
      "    \"교육\"\n",
      "  ],\n",
      "  \"도메인\": \"세계\",\n",
      "  \"근거\": \"기사 제목에서 다양한 국가, 정치적 사건, 경제 이슈, 국제 관계 등 세계적인 주제들이 나타나고 있습니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "df_6 = noisy_df[noisy_df['target']==6]\n",
    "list_6 = df_6['text'].to_list()\n",
    "examples = list_6\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 특수문자 비율의 threshold를 0.25로 했을 때, target 4의 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Count     Ratio\n",
      "target                 \n",
      "3          50  0.187266\n",
      "6          46  0.172285\n",
      "2          43  0.161049\n",
      "5          39  0.146067\n",
      "0          37  0.138577\n",
      "1          30  0.112360\n",
      "4          22  0.082397\n"
     ]
    }
   ],
   "source": [
    "noisy_df = pd.read_csv('basic_noisy_25.csv')\n",
    "noisy_df = noisy_df.drop(columns=['Unnamed: 0', 'target_name', 're_text'])\n",
    "\n",
    "# 각 target별 개수와 비율 구하기\n",
    "target_counts = noisy_df['target'].value_counts()\n",
    "target_ratios = noisy_df['target'].value_counts(normalize=True)\n",
    "\n",
    "# 결과 출력\n",
    "result_df = pd.DataFrame({\n",
    "    'Count': target_counts,\n",
    "    'Ratio': target_ratios\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"keywords\": [\n",
      "    \"스마트폰\",\n",
      "    \"모바일\",\n",
      "    \"로봇\",\n",
      "    \"아이폰\",\n",
      "    \"개발자\",\n",
      "    \"게임\",\n",
      "    \"기술\",\n",
      "    \"인공지능\",\n",
      "    \"디지털\",\n",
      "    \"시큐리티\",\n",
      "    \"전자파\",\n",
      "    \"화이트 그래핀\",\n",
      "    \"콘텐츠\",\n",
      "    \"5G\",\n",
      "    \"반도체\",\n",
      "    \"수급\",\n",
      "    \"패널\",\n",
      "    \"고속인터넷\",\n",
      "    \"목성\",\n",
      "    \"챗봇\",\n",
      "    \"데이터\"\n",
      "  ],\n",
      "  \"domain\": \"기술\",\n",
      "  \"reason\": \"제공된 기사 제목들은 스마트폰, 로봇, 인공지능, 게임, 반도체 등 기술 분야를 다루고 있습니다. 또한 디지털 콘텐츠, 시큐리티, 전자파, 5G와 같은 키워드가 나타나 기술 발전과 관련된 주제들을 보여줍니다.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "classifier = create_domain_classifier(llm)\n",
    "\n",
    "df_4 = noisy_df[noisy_df['target']==4]\n",
    "list_4 = df_4['text'].to_list()\n",
    "examples = list_4\n",
    "\n",
    "results = classifier(examples)\n",
    "print(json.dumps(results, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 도메인이 예측한 {target: 도메인}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['문화', '스포츠', '정치', '사회', '기술', '경제', '세계']\n",
    "\n",
    "target_to_domain = {\n",
    "    '문화': 0,\n",
    "    '스포츠': 1,\n",
    "    '정치': 2,\n",
    "    '사회': 3,\n",
    "    '기술': 4,\n",
    "    '경제': 5,\n",
    "    '세계': 6\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM 키워드 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>K찰.국DLwo 로L3한N% 회장 2 T0&amp;}송=</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m 김정) 자주통일 새,?r열1나가야1보</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pI美대선I앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00006</td>\n",
       "      <td>프로야구~롯TKIAs광주 경기 y천취소</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>ynat-v1_train_02787</td>\n",
       "      <td>13이 노바 라이n2·미J어패0 T3 10 결G상품% *</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>ynat-v1_train_02788</td>\n",
       "      <td>남원소식 춘&gt;X학%단+장Rn 모집</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>ynat-v1_train_02789</td>\n",
       "      <td>이총리,세4. H직 완fl지 못해E할 일 꽤;남아</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>ynat-v1_train_02792</td>\n",
       "      <td>높`X#E율…}BO Q\"[/선수 몸값 상승 CAO</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>ynat-v1_train_02797</td>\n",
       "      <td>텔레그램+한D 등h亞서 2시간H다운…C버T정gf39종!2보</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1587 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                              text  target\n",
       "0     ynat-v1_train_00000  정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보       4\n",
       "1     ynat-v1_train_00001       K찰.국DLwo 로L3한N% 회장 2 T0&}송=       3\n",
       "2     ynat-v1_train_00002            m 김정) 자주통일 새,?r열1나가야1보       2\n",
       "3     ynat-v1_train_00004      pI美대선I앞두고 R2fr단 발] $비해 감시 강화       6\n",
       "4     ynat-v1_train_00006             프로야구~롯TKIAs광주 경기 y천취소       1\n",
       "...                   ...                               ...     ...\n",
       "1582  ynat-v1_train_02787   13이 노바 라이n2·미J어패0 T3 10 결G상품% *       6\n",
       "1583  ynat-v1_train_02788                남원소식 춘>X학%단+장Rn 모집       0\n",
       "1584  ynat-v1_train_02789       이총리,세4. H직 완fl지 못해E할 일 꽤;남아       2\n",
       "1585  ynat-v1_train_02792       높`X#E율…}BO Q\"[/선수 몸값 상승 CAO       1\n",
       "1586  ynat-v1_train_02797  텔레그램+한D 등h亞서 2시간H다운…C버T정gf39종!2보       4\n",
       "\n",
       "[1587 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noisy_df = pd.read_csv('../train_noisy.csv')\n",
    "noisy_df = noisy_df.drop(columns=['target_name', 're_text'])\n",
    "noisy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Count     Ratio\n",
      "target                 \n",
      "6         229  0.144297\n",
      "2         228  0.143667\n",
      "5         227  0.143037\n",
      "3         226  0.142407\n",
      "4         226  0.142407\n",
      "0         226  0.142407\n",
      "1         225  0.141777\n"
     ]
    }
   ],
   "source": [
    "# 각 target별 개수와 비율 구하기\n",
    "target_counts = noisy_df['target'].value_counts()\n",
    "target_ratios = noisy_df['target'].value_counts(normalize=True)\n",
    "\n",
    "# 결과 출력\n",
    "result_df = pd.DataFrame({\n",
    "    'Count': target_counts,\n",
    "    'Ratio': target_ratios\n",
    "})\n",
    "\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보</td>\n",
       "      <td>기술</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>K찰.국DLwo 로L3한N% 회장 2 T0&amp;}송=</td>\n",
       "      <td>사회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>m 김정) 자주통일 새,?r열1나가야1보</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>pI美대선I앞두고 R2fr단 발] $비해 감시 강화</td>\n",
       "      <td>세계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00006</td>\n",
       "      <td>프로야구~롯TKIAs광주 경기 y천취소</td>\n",
       "      <td>스포츠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>ynat-v1_train_02787</td>\n",
       "      <td>13이 노바 라이n2·미J어패0 T3 10 결G상품% *</td>\n",
       "      <td>세계</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>ynat-v1_train_02788</td>\n",
       "      <td>남원소식 춘&gt;X학%단+장Rn 모집</td>\n",
       "      <td>문화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>ynat-v1_train_02789</td>\n",
       "      <td>이총리,세4. H직 완fl지 못해E할 일 꽤;남아</td>\n",
       "      <td>정치</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>ynat-v1_train_02792</td>\n",
       "      <td>높`X#E율…}BO Q\"[/선수 몸값 상승 CAO</td>\n",
       "      <td>스포츠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>ynat-v1_train_02797</td>\n",
       "      <td>텔레그램+한D 등h亞서 2시간H다운…C버T정gf39종!2보</td>\n",
       "      <td>기술</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1587 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID                              text target\n",
       "0     ynat-v1_train_00000  정i :파1 미사z KT( 이용기간 2e 단] Q분종U2보     기술\n",
       "1     ynat-v1_train_00001       K찰.국DLwo 로L3한N% 회장 2 T0&}송=     사회\n",
       "2     ynat-v1_train_00002            m 김정) 자주통일 새,?r열1나가야1보     정치\n",
       "3     ynat-v1_train_00004      pI美대선I앞두고 R2fr단 발] $비해 감시 강화     세계\n",
       "4     ynat-v1_train_00006             프로야구~롯TKIAs광주 경기 y천취소    스포츠\n",
       "...                   ...                               ...    ...\n",
       "1582  ynat-v1_train_02787   13이 노바 라이n2·미J어패0 T3 10 결G상품% *     세계\n",
       "1583  ynat-v1_train_02788                남원소식 춘>X학%단+장Rn 모집     문화\n",
       "1584  ynat-v1_train_02789       이총리,세4. H직 완fl지 못해E할 일 꽤;남아     정치\n",
       "1585  ynat-v1_train_02792       높`X#E율…}BO Q\"[/선수 몸값 상승 CAO    스포츠\n",
       "1586  ynat-v1_train_02797  텔레그램+한D 등h亞서 2시간H다운…C버T정gf39종!2보     기술\n",
       "\n",
       "[1587 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain_to_target = {v: k for k, v in target_to_domain.items()}\n",
    "\n",
    "# noisy_df의 target 열을 텍스트로 변환\n",
    "noisy_df['target'] = noisy_df['target'].map(domain_to_target)\n",
    "noisy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "import json\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def create_domain_keyword_extractor(llm):\n",
    "    \"\"\"도메인별 키워드 추출기 생성\"\"\"\n",
    "    \n",
    "    # JSON 출력 파서 초기화\n",
    "    parser = JsonOutputParser()\n",
    "    \n",
    "    # 프롬프트 템플릿 설정\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         '''당신은 여러 텍스트를 분석하여 해당 도메인을 대표하는 핵심 키워드를 추출하는 전문가입니다.\n",
    "         주어진 텍스트들은 모두 같은 도메인에 속하며, 텍스트에 노이즈가 첨가되어있습니다.\n",
    "         이 텍스트들을 분석하여 다음을 만족하는 키워드를 추출해주세요.\n",
    "         \n",
    "         1. 해당 도메인을 가장 잘 나타내는 핵심 키워드 50개를 추출해주세요\n",
    "         2. 키워드는 해당 도메인을 다른 도메인과 구분 짓는 특징적인 단어여야 합니다\n",
    "         3. 일반적인 단어보다는 도메인 특화된 전문 용어나 고유명사를 선호합니다\n",
    "         4. 추출된 키워드는 중요도 순으로 정렬해주세요\n",
    "         \n",
    "         현재 분석 중인 도메인: {domain}\n",
    "         '''),\n",
    "        (\"human\", \n",
    "         '''다음 텍스트들을 분석하여 도메인 특화된 키워드를 추출해주세요:\n",
    "         \n",
    "         텍스트들: {examples}\n",
    "         \n",
    "         {format_instructions}\n",
    "         ''')\n",
    "    ])\n",
    "    \n",
    "    # 체인 생성\n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    def extract_keywords(domain: str, texts: List[str]) -> List[str]:\n",
    "        \"\"\"특정 도메인의 텍스트들에서 키워드 추출\"\"\"\n",
    "        response = chain.invoke({\n",
    "            \"domain\": domain,\n",
    "            \"examples\": \"\\n\".join(texts),\n",
    "            \"format_instructions\": \"\"\"출력은 다음 JSON 형식이어야 합니다:\n",
    "            {\n",
    "                \"keywords\": [\"키워드1\", \"키워드2\", ...]\n",
    "            }\"\"\"\n",
    "        })\n",
    "        return response[\"keywords\"]\n",
    "    \n",
    "    return extract_keywords\n",
    "\n",
    "def process_domains_and_save(noisy_df: pd.DataFrame, llm, output_path: str = \"domain_keywords.csv\"):\n",
    "    \"\"\"모든 도메인의 텍스트를 처리하고 결과를 CSV로 저장\"\"\"\n",
    "    \n",
    "    # 키워드 추출기 생성\n",
    "    extractor = create_domain_keyword_extractor(llm)\n",
    "    \n",
    "    # 도메인별 키워드 저장할 딕셔너리\n",
    "    domain_keywords = defaultdict(list)\n",
    "    \n",
    "    # 각 도메인별로 처리\n",
    "    for domain in noisy_df['target'].unique():\n",
    "        # 해당 도메인의 텍스트만 추출\n",
    "        domain_texts = noisy_df[noisy_df['target'] == domain]['text'].tolist()\n",
    "        \n",
    "        # 키워드 추출\n",
    "        keywords = extractor(domain, domain_texts)\n",
    "        \n",
    "        # 결과 저장\n",
    "        domain_keywords[domain] = keywords\n",
    "    \n",
    "    # 결과를 데이터프레임으로 변환\n",
    "    # 가장 긴 키워드 리스트 길이 찾기\n",
    "    max_keywords = max(len(keywords) for keywords in domain_keywords.values())\n",
    "    \n",
    "    # 모든 리스트를 같은 길이로 맞추기 (짧은 리스트는 None으로 패딩)\n",
    "    for domain in domain_keywords:\n",
    "        domain_keywords[domain].extend([None] * (max_keywords - len(domain_keywords[domain])))\n",
    "    \n",
    "    # 데이터프레임 생성 및 저장\n",
    "    result_df = pd.DataFrame(domain_keywords)\n",
    "    result_df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            기술      사회    정치               세계   스포츠     경제      문화\n",
      "0         삼성전자    노동실태  국정원장      중국 해외투자 안전도  프로농구     경기      만화\n",
      "1  5GX MES 플랫폼     교육부  朴대통령     3중 대사관 조기 게양    축구    부동산   독립선언문\n",
      "2         스마트폰  어린이 안전    북한    한아세 베트남 관계 악화   김재현     금리     사진전\n",
      "3        디스플레이    한국노총   김정은  페루 대통령 정치 공정 제안   손흥민     외환   사진미술관\n",
      "4         지문인식    사회복지   무수성        이스라엘 정보당국   류현진  인플레이션  전국리기대회\n"
     ]
    }
   ],
   "source": [
    "# 결과 생성 및 저장\n",
    "result_df = process_domains_and_save(noisy_df, llm, \"domain_keywords_word.csv\")\n",
    "\n",
    "# 결과 확인\n",
    "print(result_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텍스트마다 키워드 뽑고, 중복 제거하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List, Set\n",
    "import json\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def create_text_keyword_extractor(llm):\n",
    "    \"\"\"개별 텍스트에서 키워드를 추출하는 함수 생성\"\"\"\n",
    "    \n",
    "    # JSON 출력 파서 초기화\n",
    "    parser = JsonOutputParser()\n",
    "    \n",
    "    # 프롬프트 템플릿 설정\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         '''당신은 텍스트를 분석하여 가장 중요한 키워드를 추출하는 전문가입니다.\n",
    "         주어진 텍스트는 {target} 도메인에 속합니다. 이 텍스트를 분석하여:\n",
    "         \n",
    "         1. 텍스트의 핵심 내용을 가장 잘 나타내는 1-2개의 키워드만 추출해주세요\n",
    "         2. 키워드는 해당 도메인을 특징짓는 전문 용어나 고유명사여야 합니다\n",
    "         3. 일반적인 단어는 제외하고, 도메인 특화된 단어만 선택해주세요\n",
    "         4. 적절한 키워드가 없다면 빈 리스트를 반환해도 됩니다\n",
    "         '''),\n",
    "        (\"human\", \n",
    "         '''다음 텍스트에서 {target} 도메인의 핵심 키워드를 1-2개만 추출해주세요:\n",
    "         \n",
    "         텍스트: {text}\n",
    "         \n",
    "         {format_instructions}\n",
    "         ''')\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    def extract_keywords(target: str, text: str) -> List[str]:\n",
    "        \"\"\"단일 텍스트에서 키워드 추출\"\"\"\n",
    "        response = chain.invoke({\n",
    "            \"target\": target,\n",
    "            \"text\": text,\n",
    "            \"format_instructions\": \"\"\"출력은 다음 JSON 형식이어야 합니다:\n",
    "            {\n",
    "                \"keywords\": [\"키워드1\"] 또는 [\"키워드1\", \"키워드2\"] 또는 []\n",
    "            }\"\"\"\n",
    "        })\n",
    "        return response[\"keywords\"]\n",
    "    \n",
    "    return extract_keywords\n",
    "\n",
    "def process_target_texts(df_target: pd.DataFrame, target: str, llm) -> Dict:\n",
    "    \"\"\"특정 타겟의 모든 텍스트를 처리하고 결과 저장\"\"\"\n",
    "    \n",
    "    # 키워드 추출기 생성\n",
    "    extractor = create_text_keyword_extractor(llm)\n",
    "    \n",
    "    # 모든 키워드를 저장할 세트 (중복 자동 제거)\n",
    "    all_keywords = set()\n",
    "    \n",
    "    # 각 텍스트별로 처리\n",
    "    for idx, text in enumerate(df_target['text']):\n",
    "        try:\n",
    "            # 키워드 추출\n",
    "            keywords = extractor(target, text)\n",
    "            # 추출된 키워드가 있으면 세트에 추가\n",
    "            all_keywords.update(keywords)\n",
    "            \n",
    "            # 진행상황 출력 (선택사항)\n",
    "            if (idx + 1) % 10 == 0:\n",
    "                print(f\"{target} 도메인: {idx + 1}/{len(df_target)} 텍스트 처리 완료\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"텍스트 처리 중 오류 발생: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 결과 딕셔너리 생성\n",
    "    result = {\n",
    "        \"target\": target,\n",
    "        \"keywords\": list(all_keywords)  # 중복이 제거된 키워드 리스트\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "def save_keywords(result: Dict, output_dir: str = \"keywords\"):\n",
    "    \"\"\"추출된 키워드를 JSON 파일로 저장\"\"\"\n",
    "    import os\n",
    "    \n",
    "    # 저장 디렉토리 생성\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # JSON 파일로 저장\n",
    "    target = result[\"target\"]\n",
    "    output_path = os.path.join(output_dir, f\"{target}_keywords.json\")\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "def combine_all_keywords(output_dir: str, output_path: str = \"all_keywords.csv\"):\n",
    "    \"\"\"저장된 모든 JSON 파일을 읽어서 하나의 DataFrame으로 통합\"\"\"\n",
    "    import os\n",
    "    import glob\n",
    "    \n",
    "    # 모든 JSON 파일 읽기\n",
    "    json_files = glob.glob(os.path.join(output_dir, \"*_keywords.json\"))\n",
    "    \n",
    "    # 결과를 저장할 딕셔너리\n",
    "    all_keywords = {}\n",
    "    \n",
    "    # 각 JSON 파일 처리\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            all_keywords[data['target']] = data['keywords']\n",
    "    \n",
    "    # DataFrame 생성\n",
    "    # 가장 긴 키워드 리스트 찾기\n",
    "    max_len = max(len(keywords) for keywords in all_keywords.values())\n",
    "    \n",
    "    # 길이 맞추기\n",
    "    for target in all_keywords:\n",
    "        all_keywords[target].extend([None] * (max_len - len(all_keywords[target])))\n",
    "    \n",
    "    # DataFrame 생성 및 저장\n",
    "    df = pd.DataFrame(all_keywords)\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문화 도메인: 10/226 텍스트 처리 완료\n",
      "문화 도메인: 20/226 텍스트 처리 완료\n",
      "문화 도메인: 30/226 텍스트 처리 완료\n",
      "문화 도메인: 40/226 텍스트 처리 완료\n",
      "문화 도메인: 50/226 텍스트 처리 완료\n",
      "문화 도메인: 60/226 텍스트 처리 완료\n",
      "문화 도메인: 70/226 텍스트 처리 완료\n",
      "문화 도메인: 80/226 텍스트 처리 완료\n",
      "문화 도메인: 90/226 텍스트 처리 완료\n",
      "문화 도메인: 100/226 텍스트 처리 완료\n",
      "문화 도메인: 110/226 텍스트 처리 완료\n",
      "문화 도메인: 120/226 텍스트 처리 완료\n",
      "문화 도메인: 130/226 텍스트 처리 완료\n",
      "문화 도메인: 140/226 텍스트 처리 완료\n",
      "문화 도메인: 150/226 텍스트 처리 완료\n",
      "문화 도메인: 160/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: {\n",
      "    \"keywords\": []\n",
      "} \n",
      "\n",
      "\n",
      "주어진 텍스트는 '명말청6 7기[?국7사mz들은 3IUSb아남@p' 와 같이 의미를 파악할 수 없는 형태로 제시되어 있습니다. 따라서 문화 도메인의 키워드를 추출하기 어렵습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "문화 도메인: 170/226 텍스트 처리 완료\n",
      "문화 도메인: 180/226 텍스트 처리 완료\n",
      "문화 도메인: 190/226 텍스트 처리 완료\n",
      "문화 도메인: 200/226 텍스트 처리 완료\n",
      "문화 도메인: 210/226 텍스트 처리 완료\n",
      "문화 도메인: 220/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "\n",
      "문화 도메인 처리 완료\n",
      "추출된 고유 키워드 수: 70\n",
      "스포츠 도메인: 10/225 텍스트 처리 완료\n",
      "스포츠 도메인: 20/225 텍스트 처리 완료\n",
      "스포츠 도메인: 30/225 텍스트 처리 완료\n",
      "스포츠 도메인: 40/225 텍스트 처리 완료\n",
      "스포츠 도메인: 50/225 텍스트 처리 완료\n",
      "스포츠 도메인: 60/225 텍스트 처리 완료\n",
      "스포츠 도메인: 70/225 텍스트 처리 완료\n",
      "스포츠 도메인: 80/225 텍스트 처리 완료\n",
      "스포츠 도메인: 90/225 텍스트 처리 완료\n",
      "스포츠 도메인: 100/225 텍스트 처리 완료\n",
      "스포츠 도메인: 110/225 텍스트 처리 완료\n",
      "스포츠 도메인: 120/225 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "스포츠 도메인: 130/225 텍스트 처리 완료\n",
      "스포츠 도메인: 140/225 텍스트 처리 완료\n",
      "스포츠 도메인: 150/225 텍스트 처리 완료\n",
      "스포츠 도메인: 160/225 텍스트 처리 완료\n",
      "스포츠 도메인: 170/225 텍스트 처리 완료\n",
      "스포츠 도메인: 180/225 텍스트 처리 완료\n",
      "스포츠 도메인: 190/225 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "  \"keywords\": []\n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "텍스트 분석 결과, 스포츠 도메인의 전문 용어나 고유명사가 파악되지 않았습니다.  *v준우*, *F[만 g각한다* 와 같은 문자는 의미를 가질 수 없거나 잘못된 입력일 가능성이 높습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "스포츠 도메인: 200/225 텍스트 처리 완료\n",
      "스포츠 도메인: 210/225 텍스트 처리 완료\n",
      "스포츠 도메인: 220/225 텍스트 처리 완료\n",
      "\n",
      "스포츠 도메인 처리 완료\n",
      "추출된 고유 키워드 수: 143\n",
      "정치 도메인: 10/228 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "정치 도메인: 20/228 텍스트 처리 완료\n",
      "정치 도메인: 30/228 텍스트 처리 완료\n",
      "정치 도메인: 40/228 텍스트 처리 완료\n",
      "정치 도메인: 50/228 텍스트 처리 완료\n",
      "정치 도메인: 60/228 텍스트 처리 완료\n",
      "정치 도메인: 70/228 텍스트 처리 완료\n",
      "정치 도메인: 80/228 텍스트 처리 완료\n",
      "정치 도메인: 90/228 텍스트 처리 완료\n",
      "정치 도메인: 100/228 텍스트 처리 완료\n",
      "정치 도메인: 110/228 텍스트 처리 완료\n",
      "정치 도메인: 120/228 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "정치 도메인: 130/228 텍스트 처리 완료\n",
      "정치 도메인: 140/228 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      " \"keywords\": [\"남북상\", ]\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "정치 도메인: 160/228 텍스트 처리 완료\n",
      "정치 도메인: 170/228 텍스트 처리 완료\n",
      "정치 도메인: 180/228 텍스트 처리 완료\n",
      "정치 도메인: 190/228 텍스트 처리 완료\n",
      "정치 도메인: 200/228 텍스트 처리 완료\n",
      "정치 도메인: 210/228 텍스트 처리 완료\n",
      "정치 도메인: 220/228 텍스트 처리 완료\n",
      "\n",
      "정치 도메인 처리 완료\n",
      "추출된 고유 키워드 수: 127\n",
      "사회 도메인: 10/226 텍스트 처리 완료\n",
      "사회 도메인: 20/226 텍스트 처리 완료\n",
      "사회 도메인: 30/226 텍스트 처리 완료\n",
      "사회 도메인: 40/226 텍스트 처리 완료\n",
      "사회 도메인: 50/226 텍스트 처리 완료\n",
      "사회 도메인: 60/226 텍스트 처리 완료\n",
      "사회 도메인: 70/226 텍스트 처리 완료\n",
      "사회 도메인: 80/226 텍스트 처리 완료\n",
      "사회 도메인: 90/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      " \"keywords\": [\"아나운서\", \"이화V론/클럽 회\"],\n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "**해설:**\n",
      "\n",
      "*  \"아나운서\"는 방송 및 매체 분야의 전문 용어입니다.\n",
      "* \"이화V론/클럽 회\" 는  특정 단체 또는 행사를 가리키는 고유명사입니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "사회 도메인: 100/226 텍스트 처리 완료\n",
      "사회 도메인: 110/226 텍스트 처리 완료\n",
      "사회 도메인: 120/226 텍스트 처리 완료\n",
      "사회 도메인: 130/226 텍스트 처리 완료\n",
      "사회 도메인: 140/226 텍스트 처리 완료\n",
      "사회 도메인: 150/226 텍스트 처리 완료\n",
      "사회 도메인: 160/226 텍스트 처리 완료\n",
      "사회 도메인: 170/226 텍스트 처리 완료\n",
      "사회 도메인: 180/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      " \"keywords\": [\"노동실태\"] \n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "**해설:**\n",
      "\n",
      "*  '방역장비', '자동차'는 일반적인 용어이며, 도메인 특화된 단어로 보기 어렵습니다.\n",
      "* 'ZZ땀', 'K자동차', '[비=o' 와 같은 부분은 문맥상 명확한 의미를 파악하기 어렵습니다.\n",
      "* 따라서 사회 도메인의 핵심 키워드로는 '노동실태'만을 추출했습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "사회 도메인: 190/226 텍스트 처리 완료\n",
      "사회 도메인: 200/226 텍스트 처리 완료\n",
      "사회 도메인: 210/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'keywords'\n",
      "사회 도메인: 220/226 텍스트 처리 완료\n",
      "\n",
      "사회 도메인 처리 완료\n",
      "추출된 고유 키워드 수: 144\n",
      "기술 도메인: 10/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "기술 도메인: 20/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "기술 도메인: 30/226 텍스트 처리 완료\n",
      "기술 도메인: 40/226 텍스트 처리 완료\n",
      "기술 도메인: 50/226 텍스트 처리 완료\n",
      "기술 도메인: 60/226 텍스트 처리 완료\n",
      "기술 도메인: 70/226 텍스트 처리 완료\n",
      "기술 도메인: 80/226 텍스트 처리 완료\n",
      "기술 도메인: 90/226 텍스트 처리 완료\n",
      "기술 도메인: 100/226 텍스트 처리 완료\n",
      "기술 도메인: 110/226 텍스트 처리 완료\n",
      "기술 도메인: 120/226 텍스트 처리 완료\n",
      "기술 도메인: 130/226 텍스트 처리 완료\n",
      "기술 도메인: 140/226 텍스트 처리 완료\n",
      "기술 도메인: 150/226 텍스트 처리 완료\n",
      "기술 도메인: 160/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "기술 도메인: 170/226 텍스트 처리 완료\n",
      "기술 도메인: 180/226 텍스트 처리 완료\n",
      "기술 도메인: 190/226 텍스트 처리 완료\n",
      "기술 도메인: 200/226 텍스트 처리 완료\n",
      "기술 도메인: 210/226 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "\n",
      "기술 도메인 처리 완료\n",
      "추출된 고유 키워드 수: 89\n",
      "경제 도메인: 10/227 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      " \"keywords\": [\"공공주택\",  ]\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "경제 도메인: 20/227 텍스트 처리 완료\n",
      "경제 도메인: 30/227 텍스트 처리 완료\n",
      "경제 도메인: 40/227 텍스트 처리 완료\n",
      "경제 도메인: 50/227 텍스트 처리 완료\n",
      "경제 도메인: 60/227 텍스트 처리 완료\n",
      "경제 도메인: 70/227 텍스트 처리 완료\n",
      "경제 도메인: 80/227 텍스트 처리 완료\n",
      "경제 도메인: 90/227 텍스트 처리 완료\n",
      "경제 도메인: 100/227 텍스트 처리 완료\n",
      "경제 도메인: 110/227 텍스트 처리 완료\n",
      "경제 도메인: 120/227 텍스트 처리 완료\n",
      "경제 도메인: 130/227 텍스트 처리 완료\n",
      "경제 도메인: 140/227 텍스트 처리 완료\n",
      "경제 도메인: 150/227 텍스트 처리 완료\n",
      "경제 도메인: 160/227 텍스트 처리 완료\n",
      "경제 도메인: 170/227 텍스트 처리 완료\n",
      "경제 도메인: 180/227 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "경제 도메인: 190/227 텍스트 처리 완료\n",
      "경제 도메인: 200/227 텍스트 처리 완료\n",
      "경제 도메인: 210/227 텍스트 처리 완료\n",
      "경제 도메인: 220/227 텍스트 처리 완료\n",
      "\n",
      "경제 도메인 처리 완료\n",
      "추출된 고유 키워드 수: 93\n",
      "세계 도메인: 10/229 텍스트 처리 완료\n",
      "세계 도메인: 20/229 텍스트 처리 완료\n",
      "세계 도메인: 30/229 텍스트 처리 완료\n",
      "세계 도메인: 40/229 텍스트 처리 완료\n",
      "세계 도메인: 50/229 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "  \"keywords\": [\"중국/미 간\"]) \n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "세계 도메인: 70/229 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      " \"keywords\": [\"중동\",  ]\n",
      "}\n",
      "```\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "세계 도메인: 80/229 텍스트 처리 완료\n",
      "세계 도메인: 90/229 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "세계 도메인: 100/229 텍스트 처리 완료\n",
      "세계 도메인: 110/229 텍스트 처리 완료\n",
      "세계 도메인: 120/229 텍스트 처리 완료\n",
      "세계 도메인: 130/229 텍스트 처리 완료\n",
      "세계 도메인: 140/229 텍스트 처리 완료\n",
      "세계 도메인: 150/229 텍스트 처리 완료\n",
      "세계 도메인: 160/229 텍스트 처리 완료\n",
      "세계 도메인: 170/229 텍스트 처리 완료\n",
      "세계 도메인: 180/229 텍스트 처리 완료\n",
      "세계 도메인: 190/229 텍스트 처리 완료\n",
      "세계 도메인: 200/229 텍스트 처리 완료\n",
      "세계 도메인: 210/229 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "세계 도메인: 220/229 텍스트 처리 완료\n",
      "텍스트 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      " \"keywords\": [\"예멘 전쟁\",] \n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "**해설:**\n",
      "\n",
      "*  \"특M\", \"반P·정부d긴급 면담O.전m이, 촉구\" 는 구체적인 이슈나 사건을 나타내는 단어로 해석 가능하지만, 예멘 전쟁의 맥락 속에서 이해할 수 있습니다.\n",
      "* 세계 도메인에 속하는 키워드 중 가장 적합한 것은 \"예멘 전쟁\"입니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "\n",
      "세계 도메인 처리 완료\n",
      "추출된 고유 키워드 수: 51\n",
      "         기술       사회     문화      스포츠    경제          세계     정치\n",
      "0       py체  대외고 통학차   스포X카      득점왕  기업수익          대선     국회\n",
      "1  뉴욕 필름 페스     미세먼지    교향곡      MLB    배당       협약 이행   책 추진\n",
      "2    아이펀팩`리      교황청   포퓰리즘      올림픽  경기침체        해상N력  소통 강화\n",
      "3        왓x      항소심     불교     바셀로나    합병        정상회의  국회사무처\n",
      "4    AI 업지능       파장  모z르트w  바르사 빌바오   부품주  美4中Z군사적 충돌    올림픽\n"
     ]
    }
   ],
   "source": [
    "# 각 타겟별로 처리\n",
    "targets = ['문화', '스포츠', '정치', '사회', '기술', '경제', '세계']\n",
    "for target in targets:\n",
    "    # 타겟별 데이터 추출\n",
    "    df_target = noisy_df[noisy_df['target'] == target]\n",
    "    \n",
    "    # 키워드 추출 및 중복 제거\n",
    "    result = process_target_texts(df_target, target, llm)\n",
    "    \n",
    "    # 결과 저장\n",
    "    save_keywords(result)\n",
    "    print(f\"\\n{target} 도메인 처리 완료\")\n",
    "    print(f\"추출된 고유 키워드 수: {len(result['keywords'])}\")\n",
    "\n",
    "# 모든 결과 통합\n",
    "final_df = combine_all_keywords('keywords', 'all_domain_keywords.csv')\n",
    "print(final_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>기술</th>\n",
       "      <th>사회</th>\n",
       "      <th>문화</th>\n",
       "      <th>스포츠</th>\n",
       "      <th>경제</th>\n",
       "      <th>세계</th>\n",
       "      <th>정치</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>py체</td>\n",
       "      <td>대외고 통학차</td>\n",
       "      <td>스포X카</td>\n",
       "      <td>득점왕</td>\n",
       "      <td>기업수익</td>\n",
       "      <td>대선</td>\n",
       "      <td>국회</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>뉴욕 필름 페스</td>\n",
       "      <td>미세먼지</td>\n",
       "      <td>교향곡</td>\n",
       "      <td>MLB</td>\n",
       "      <td>배당</td>\n",
       "      <td>협약 이행</td>\n",
       "      <td>책 추진</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>아이펀팩`리</td>\n",
       "      <td>교황청</td>\n",
       "      <td>포퓰리즘</td>\n",
       "      <td>올림픽</td>\n",
       "      <td>경기침체</td>\n",
       "      <td>해상N력</td>\n",
       "      <td>소통 강화</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>왓x</td>\n",
       "      <td>항소심</td>\n",
       "      <td>불교</td>\n",
       "      <td>바셀로나</td>\n",
       "      <td>합병</td>\n",
       "      <td>정상회의</td>\n",
       "      <td>국회사무처</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AI 업지능</td>\n",
       "      <td>파장</td>\n",
       "      <td>모z르트w</td>\n",
       "      <td>바르사 빌바오</td>\n",
       "      <td>부품주</td>\n",
       "      <td>美4中Z군사적 충돌</td>\n",
       "      <td>올림픽</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>None</td>\n",
       "      <td>거제 E0 출입제한</td>\n",
       "      <td>None</td>\n",
       "      <td>도전</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>None</td>\n",
       "      <td>지방자치단체</td>\n",
       "      <td>None</td>\n",
       "      <td>두산</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>None</td>\n",
       "      <td>D식종&amp;자</td>\n",
       "      <td>None</td>\n",
       "      <td>프로야구</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>None</td>\n",
       "      <td>민간추진협의회</td>\n",
       "      <td>None</td>\n",
       "      <td>루카쿠</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>None</td>\n",
       "      <td>LG화학</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>144 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           기술          사회     문화      스포츠    경제          세계     정치\n",
       "0         py체     대외고 통학차   스포X카      득점왕  기업수익          대선     국회\n",
       "1    뉴욕 필름 페스        미세먼지    교향곡      MLB    배당       협약 이행   책 추진\n",
       "2      아이펀팩`리         교황청   포퓰리즘      올림픽  경기침체        해상N력  소통 강화\n",
       "3          왓x         항소심     불교     바셀로나    합병        정상회의  국회사무처\n",
       "4      AI 업지능          파장  모z르트w  바르사 빌바오   부품주  美4中Z군사적 충돌    올림픽\n",
       "..        ...         ...    ...      ...   ...         ...    ...\n",
       "139      None  거제 E0 출입제한   None       도전  None        None   None\n",
       "140      None      지방자치단체   None       두산  None        None   None\n",
       "141      None       D식종&자   None     프로야구  None        None   None\n",
       "142      None     민간추진협의회   None      루카쿠  None        None   None\n",
       "143      None        LG화학   None     None  None        None   None\n",
       "\n",
       "[144 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Noisy text 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "import json\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "def create_text_restorer(llm):\n",
    "    \"\"\"텍스트 복원기 생성\"\"\"\n",
    "    \n",
    "    # JSON 출력 파서 초기화\n",
    "    parser = JsonOutputParser()\n",
    "    \n",
    "    # 프롬프트 템플릿 설정\n",
    "    prompt = ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \n",
    "         '''당신은 노이즈가 낀 텍스트를 원래의 뉴스 기사 제목으로 복원하는 전문가입니다.\n",
    "         주어진 텍스트는 {target} 도메인의 뉴스 기사 제목이었으나 노이즈가 끼었습니다.\n",
    "         \n",
    "         복원 규칙:\n",
    "         1. 노이즈가 낀 텍스트를 보고 원래 의미를 파악할 수 있다면, 해당 의미를 살려 복원해주세요\n",
    "         2. 텍스트가 너무 손상되어 의미 파악이 어렵다면, 제공된 키워드 리스트에서 적절한 키워드를 선택해 \n",
    "            {target} 도메인에 맞는 새로운 뉴스 기사 제목을 생성해주세요\n",
    "         3. 복원된 텍스트의 길이는 원본 텍스트의 글자 수와 최대한 비슷하게 맞춰주세요\n",
    "            (원본 길이: {original_length}자)\n",
    "         4. 복원 방식(복원/생성)을 명시해주세요\n",
    "         '''),\n",
    "        (\"human\", \n",
    "         '''다음 정보를 바탕으로 텍스트를 복원해주세요:\n",
    "         \n",
    "         도메인: {target}\n",
    "         노이즈가 낀 텍스트: {noisy_text}\n",
    "         참고 키워드 리스트: {keywords}\n",
    "         \n",
    "         {format_instructions}\n",
    "         ''')\n",
    "    ])\n",
    "    \n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    def restore_text(target: str, noisy_text: str, keywords: List[str]) -> Dict:\n",
    "        \"\"\"텍스트 복원 실행\"\"\"\n",
    "        response = chain.invoke({\n",
    "            \"target\": target,\n",
    "            \"noisy_text\": noisy_text,\n",
    "            \"keywords\": \", \".join(keywords),\n",
    "            \"original_length\": len(noisy_text),\n",
    "            \"format_instructions\": \"\"\"출력은 다음 JSON 형식이어야 합니다:\n",
    "            {\n",
    "                \"restored_text\": \"복원된 텍스트\",\n",
    "                \"method\": \"복원\" 또는 \"생성\"\n",
    "            }\"\"\"\n",
    "        })\n",
    "        return response\n",
    "    \n",
    "    return restore_text\n",
    "\n",
    "def process_dataframe(noisy_df: pd.DataFrame, keyword_df: pd.DataFrame, llm) -> pd.DataFrame:\n",
    "    \"\"\"전체 데이터프레임 처리\"\"\"\n",
    "    \n",
    "    # 결과를 저장할 새로운 데이터프레임 생성\n",
    "    result_df = noisy_df.copy()\n",
    "    result_df['re_text'] = ''\n",
    "    result_df['restoration_method'] = ''\n",
    "    \n",
    "    # 텍스트 복원기 생성\n",
    "    restorer = create_text_restorer(llm)\n",
    "    \n",
    "    # 각 행별로 처리\n",
    "    for idx, row in result_df.iterrows():\n",
    "        try:\n",
    "            # 해당 타겟의 키워드 리스트 가져오기\n",
    "            target_keywords = keyword_df[row['target']].dropna().tolist()\n",
    "            \n",
    "            # 텍스트 복원\n",
    "            result = restorer(\n",
    "                target=row['target'],\n",
    "                noisy_text=row['text'],\n",
    "                keywords=target_keywords\n",
    "            )\n",
    "            \n",
    "            # 결과 저장\n",
    "            result_df.at[idx, 're_text'] = result['restored_text']\n",
    "            result_df.at[idx, 'restoration_method'] = result['method']\n",
    "            \n",
    "            # 진행상황 출력 (100개마다)\n",
    "            if (idx + 1) % 100 == 0:\n",
    "                print(f\"{idx + 1}/{len(result_df)} 처리 완료\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ID {row['ID']} 처리 중 오류 발생: {e}\")\n",
    "            result_df.at[idx, 're_text'] = row['text']  # 오류 시 원본 텍스트 유지\n",
    "            result_df.at[idx, 'restoration_method'] = 'error'\n",
    "            continue\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "def save_results(df: pd.DataFrame, output_path: str = \"restored_texts.csv\"):\n",
    "    \"\"\"결과를 CSV 파일로 저장\"\"\"\n",
    "    df.to_csv(output_path, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID ynat-v1_train_00046 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "\"restored_text\": \"5자농 R4은행 삼[m명 꺾직\",\n",
      "\"method\": \"복원\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "**해설:**\n",
      "\n",
      "주어진 노이즈가 낀 텍스트는 스포츠 관련 뉴스 제목 형태로 보이며, 일부 단어들이 잘못 표기되어 있습니다.  '5자농 R4은행 삼[m명 꺾직' 을 통해 '5자농 R4은행 삼성 명 꺾직'으로 복원할 수 있을 것으로 추정됩니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "100/1587 처리 완료\n",
      "200/1587 처리 완료\n",
      "ID ynat-v1_train_00474 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "300/1587 처리 완료\n",
      "ID ynat-v1_train_00566 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "\"restored_text\": \"한국 교향악단 오케스트라 공연\",\n",
      "\"method\": \"복원\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "\n",
      "**설명:**\n",
      "\n",
      "노이즈가 끼어있는 ' [간 @기와 ;외X 음k5quA타 3q' 에서  '교향악단', '오케스트라' 와 같은 키워드를 추출하여 원래 의미로 가정하여 복원했습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "ID ynat-v1_train_00579 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "\"restored_text\": \"영국, 레지스탕스 혼란에 C z?獨(佛…*y한 입장 제Q해\"[합\",\n",
      "\"method\": \"복원\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "**요약:**\n",
      "\n",
      "제공된 노이즈가 낀 텍스트는  '영국의'라는 부분은 분명히 보이고 있어 복원이 가능합니다. 나머지 부분은 '레지스탕스', '혼란', 'C z?獨(佛…*y한 입장 제Q해\"[합' 와 같은 불규칙적인 문자로 이루어져 원래의 의미를 파악하기 어렵습니다. 하지만,  문맥상 영국과 관련된 상황이 드러나는 부분을 살려 복원했습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "ID ynat-v1_train_00588 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "400/1587 처리 완료\n",
      "500/1587 처리 완료\n",
      "ID ynat-v1_train_00916 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "600/1587 처리 완료\n",
      "ID ynat-v1_train_01074 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "                \"restored_text\": \"문 대통령, 국회 소통 강화를 위해 노력할 것\",\n",
      "                \"method\": \"복원\"\n",
      "            }\n",
      "``` \n",
      "\n",
      "\n",
      "**복원 과정:**\n",
      "\n",
      "*  '{용차K{`관심 ;져달라N마힌Y' 부분은 문 대통령이 국회와의 소통에 신경 쓰고 있다는 것을 추론할 수 있습니다. \n",
      "* '잘 풀%갈*것종합' 부분은 문 대통령이 국회와의 소통을 통해 어떤 문제를 해결하고자 하는지, 긍정적인 방향으로 노력하겠다는 의지를 담고 있다는 것을 추론했습니다.\n",
      "\n",
      " 따라서, '문 대통령, 국회 소통 강화를 위해 노력할 것' 으로 복원되었습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "ID ynat-v1_train_01082 처리 중 오류 발생: 'method'\n",
      "ID ynat-v1_train_01108 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "700/1587 처리 완료\n",
      "800/1587 처리 완료\n",
      "ID ynat-v1_train_01420 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "\"restored_text\": \"입김불량 필름...위조방지 적용\",\n",
      "\"method\": \"복원\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "**설명:**\n",
      "\n",
      "노이즈가 심하게 끼어 있는 부분을 살펴보고 '불면증'과 같은 의미로 해석될 수 있는 단어인 'K색H변[U'를 제외하고,  '입김'과 '필름', 그리고 '위조방지 적용'이라는 문구의 의미를 파악하여 복원했습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "ID ynat-v1_train_01450 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "900/1587 처리 완료\n",
      "1000/1587 처리 완료\n",
      "1100/1587 처리 완료\n",
      "ID ynat-v1_train_01972 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "\"restored_text\": \"S현cu[M전 D<v치에=연9석fD로+xn납/6바u 9K\".replace(\" \",\" \").strip(),  \n",
      "\"method\": \"복원\"\n",
      "}\n",
      "```\n",
      "\n",
      "**해설:**\n",
      "\n",
      "노이즈가 낀 텍스트의 특성상 원래 의미를 파악하는 것은 어렵습니다. 따라서 최대한 오리지널 의미를 살린 채, 노이즈를 제거하여 복원 시도했습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "1200/1587 처리 완료\n",
      "1300/1587 처리 완료\n",
      "ID ynat-v1_train_02458 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "ID ynat-v1_train_02469 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "1400/1587 처리 완료\n",
      "1500/1587 처리 완료\n",
      "ID ynat-v1_train_02697 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "\"restored_text\": \"[반 스페인] 노란색 리본 철거지 시위\",\n",
      "\"method\": \"복원\"\n",
      "}\n",
      "``` \n",
      "\n",
      "\n",
      "**복원 이유:**\n",
      "\n",
      "*  'n탈.냐 [반 스페인' 부분은 '반 스페인'으로 해석 가능하며, 시위 주제와 관련이 있을 것으로 추정됩니다.\n",
      "* '[노란 리rO철거지]'는 '노란색 리본 철거지'로 복원할 수 있습니다. 노란색 리본은 반 정부 시위를 상징하는 색상으로 알려져 있습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "ID ynat-v1_train_02774 처리 중 오류 발생: Invalid json output: ```json\n",
      "{\n",
      "\"restored_text\": \"문제 지로드맵 n\\내#]C\",\n",
      "\"method\": \"복원\"\n",
      "}\n",
      "``` \n",
      "\n",
      "**해설:**\n",
      "\n",
      "노이즈가 심하게 끼어있지만,  '지로드맵' 라는 단어와 함께 '문제' 와의 연결은 기사 제목으로 적절한 의미를 가짐을 추론할 수 있습니다. 따라서 최대한 원본 의미를 살려 복원했습니다.\n",
      "For troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/OUTPUT_PARSING_FAILURE\n",
      "ID ynat-v1_train_02792 처리 중 오류 발생: 'NoneType' object is not subscriptable\n",
      "\n",
      "복원 방법 통계:\n",
      "restoration_method\n",
      "복원       1518\n",
      "생성         52\n",
      "error      17\n",
      "Name: count, dtype: int64\n",
      "\n",
      "복원 예시:\n",
      "\n",
      "원본: 인천서O g행된 O라/ .력평3\n",
      "복원: 인천서 교통사고 발생\n",
      "방법: 복원\n",
      "\n",
      "원본: s위7G정청=추S안7ry내 1회 본회의 W과해야\n",
      "복원: 국회 본회의 W과해야 책 추진안\n",
      "방법: 복원\n",
      "\n",
      "원본: P*페인트공업 .s 연결7영업r 88억원…54%<\n",
      "복원: 페인트공업 연결영업익 88억원…54%↑\n",
      "방법: 복원\n",
      "\n",
      "원본: 북한c조선}?TV 잠시 } 특별 중6방송 예고\n",
      "복원: 북한 조선 중앙TV 특별 방송 예고\n",
      "방법: 복원\n",
      "\n",
      "원본: 코리아^레길 민간추진협의회 2<일 출u식\n",
      "복원: 코리아레길 민간추진협의회 2일 출식\n",
      "방법: 복원\n"
     ]
    }
   ],
   "source": [
    "# 전체 데이터프레임 처리\n",
    "restored_df = process_dataframe(noisy_df, final_df, llm)\n",
    "\n",
    "# 결과 저장\n",
    "save_results(restored_df, \"restored_news_titles.csv\")\n",
    "\n",
    "# 결과 확인\n",
    "print(\"\\n복원 방법 통계:\")\n",
    "print(restored_df['restoration_method'].value_counts())\n",
    "\n",
    "# 샘플 결과 확인\n",
    "print(\"\\n복원 예시:\")\n",
    "samples = restored_df.sample(5)\n",
    "for _, row in samples.iterrows():\n",
    "    print(f\"\\n원본: {row['text']}\")\n",
    "    print(f\"복원: {row['re_text']}\")\n",
    "    print(f\"방법: {row['restoration_method']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 증강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "\n",
    "# 요청 사항 설정\n",
    "req = \"도메인을 명확하게 나타내는 뉴스 기사 제목을, 30글자가 넘지 않도록 도메인별로 30개씩 생성해 주세요.\"\n",
    "\n",
    "# JSONOutputParser 초기화\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 도메인별 요구사항\n",
    "domain_requirements = \"\"\"\n",
    "- 문화: 건강, 자동차 리뷰, 교통 상황, 여행지 추천, 맛집 탐방, 패션 트렌드, 공연 정보, 신간 도서, 만화/웹툰, 학술/문화재, 종교 행사, 기상 소식 등의 주제를 포함해야 하며, 제목은 생활 속 유용한 정보나 최신 문화 트렌드를 반영해야 합니다. 특정 활동이나 장소가 포함되면 더 좋습니다.\n",
    "- 스포츠: 야구, 축구, 농구, 배구, 골프와 관련된 스포츠 소식이나 팀 이름, 선수 이름, 경기 결과를 포함하면 좋습니다. 제목은 해당 종목의 주요 경기 소식, 팀이나 선수의 승패, 리그 경기 일정을 반영하는 내용이어야 합니다. 팬들에게 흥미를 줄 수 있도록 특정 팀, 선수, 경기 기록이 포함되면 좋습니다.\n",
    "- 정치: 대통령실, 국회, 정당 정책, 외교 관계, 국방 관련 주제로 정치적인 이슈를 다루면 좋습니다. 사회 분야와 헷갈리지 않도록 법안, 외교 협력, 정부 정책 등의 정치적 의제를 명확히 드러내고, 국내외 정치적 흐름이나 중요한 정부 발표가 포함된 제목이어야 합니다.\n",
    "- 사회: 사건/사고, 법원 판결, 교육 정책, 복지 서비스, 노동 문제, 환경 이슈, 여성과 아동 문제, 다문화 관련 주제를 다루면 좋습니다. 정치나 문화 분야와 헷갈리지 않도록, 사회적인 현안이나 공공의 문제를 강조하고, 특히 법원이나 검찰 관련 사안, 주요 사건을 포함한 제목이 좋습니다.\n",
    "- 기술: 유명 IT 기업 이름이나 신기술 관련 용어가 포함되어 기술의 발전과 변화를 잘 드러내는 제목을 만들어주세요. 최신 과학 기술, IT 산업의 발전, 기술 기업의 신제품 발표, 혁신적인 기술 트렌드와 관련되면 좋습니다. 기술의 응용이나 영향을 언급하면 더욱 좋습니다.\n",
    "- 경제: 경제 정책, 금융 시장, 부동산, 취업/창업, 소비자 관련 정보를 담기면 좋습니다. 주식, 펀드, 금리, 부동산 가격 상승/하락 등 경제 변동을 보여주는 내용을 포함하고, 특히 투자나 기업의 경제적 성장, 경기 흐름을 반영하는 제목이 좋습니다.\n",
    "- 세계: 미국, 중국, 일본, 유럽 등 국가 이름이나 국제기구와 관련된 글로벌 소식을 담기면 좋습니다. 세계적인 정세 변화를 반영하고, 국가 간 관계, 국제 협력, 글로벌 이슈와 같은 주제를 다루며, 특정 지역이나 국가의 중요 소식이 포함된 제목을 만들어주세요.\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 템플릿을 설정합니다.\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     '''당신은 특정 도메인의 기사 제목을 생성하는 어시스턴트입니다.\n",
    "     다음 조건을 기반으로 기사 제목을 생성해 주세요:\n",
    "\n",
    "     - 주어진 도메인 \"{{target}}\"을 명확하게 나타내는 한문장 내외의 적절한 뉴스 기사 제목을 30개 생성하세요.\n",
    "     - 제목은 반드시 JSON 배열 형식으로 반환하고, 도메인을 \"target\" 키로, 생성한 제목을 \"text\" 키로 표시합니다.\n",
    "\n",
    "     도메인별 요구사항:\n",
    "     {domain_requirements}\n",
    "\n",
    "     주의: 응답은 JSON 배열 형식으로만 반환해야 하며, 그 외의 텍스트는 포함하지 마세요. \n",
    "     반드시 JSON 형식으로만 반환하고, 배열의 각 항목은 {{\"target\": \"{{target}}\", \"text\": \"<생성한 제목>\"}} 형식이어야 합니다.'''),\n",
    "    (\"user\",\n",
    "     \"#Format: {format_instructions}\\n\\n#Requirements: {req}\\n\\n#Domain: {target}\")\n",
    "])\n",
    "\n",
    "# 프롬프트, 모델, 파서를 연결하는 체인 생성\n",
    "chain = prompt | llm | parser\n",
    "\n",
    "def generate_domain_titles(domains: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    여러 도메인에 대한 뉴스 제목을 생성하고 DataFrame으로 반환하는 함수\n",
    "    \n",
    "    Args:\n",
    "        domains (List[str]): 뉴스 도메인 리스트\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: target(도메인)과 text(제목) 컬럼을 가진 DataFrame\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    \n",
    "    for domain in domains:\n",
    "        try:\n",
    "            print(f\"\\n{domain} 도메인의 뉴스 제목 생성 중...\")\n",
    "            response = chain.invoke({\n",
    "                \"req\": req,\n",
    "                \"target\": domain,\n",
    "                \"domain_requirements\": domain_requirements,\n",
    "                \"format_instructions\": parser.get_format_instructions()\n",
    "            })\n",
    "            \n",
    "            # response가 None인지 확인\n",
    "            if response is None:\n",
    "                print(\"오류 발생: chain.invoke()에서 None이 반환되었습니다.\")\n",
    "            elif isinstance(response, list):  \n",
    "                data.extend(response)\n",
    "            else:\n",
    "                print(\"올바르지 않은 JSON 응답:\", response)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{domain} 도메인에서 예외 발생: {str(e)}\")\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = ['문화', '스포츠', '정치', '사회', '기술', '경제', '세계']\n",
    "\n",
    "# 뉴스 제목 생성\n",
    "df = generate_domain_titles(domains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_to_domain = {\n",
    "    '문화': 0,\n",
    "    '스포츠': 1,\n",
    "    '정치': 2,\n",
    "    '사회': 3,\n",
    "    '기술': 4,\n",
    "    '경제': 5,\n",
    "    '세계': 6\n",
    "}\n",
    "\n",
    "df['target'] = df['target'].map(target_to_domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('news_titles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>restoration_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ynat-v1_train_00000</td>\n",
       "      <td>4</td>\n",
       "      <td>KT AI 서비스 이용기간 2년 단축, Q분종 U2보</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ynat-v1_train_00001</td>\n",
       "      <td>3</td>\n",
       "      <td>K찰국 회장 노조 통합협상</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ynat-v1_train_00002</td>\n",
       "      <td>2</td>\n",
       "      <td>김정은, 북미 대화 정면돌파 필요하나?</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ynat-v1_train_00004</td>\n",
       "      <td>6</td>\n",
       "      <td>미대선 앞두고 R2프랑스 단 발 비해 감시 강화</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ynat-v1_train_00006</td>\n",
       "      <td>1</td>\n",
       "      <td>프로야구 롯데 KIA 광주 경기 취소</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1582</th>\n",
       "      <td>ynat-v1_train_02787</td>\n",
       "      <td>6</td>\n",
       "      <td>13일 노바 라이2·미군 합동演習 이루어진다.</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>ynat-v1_train_02788</td>\n",
       "      <td>0</td>\n",
       "      <td>남원소식춘향단 모집</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1584</th>\n",
       "      <td>ynat-v1_train_02789</td>\n",
       "      <td>2</td>\n",
       "      <td>이총리, 국회 직 무기대상책 추진해야</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>ynat-v1_train_02792</td>\n",
       "      <td>1</td>\n",
       "      <td>높`X#E율…}BO Q\"[/선수 몸값 상승 CAO</td>\n",
       "      <td>error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>ynat-v1_train_02797</td>\n",
       "      <td>4</td>\n",
       "      <td>텔레그램+한D 등 업계 2시간  업데이트…39종!2보</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1587 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       ID  target                           text  \\\n",
       "0     ynat-v1_train_00000       4  KT AI 서비스 이용기간 2년 단축, Q분종 U2보   \n",
       "1     ynat-v1_train_00001       3                 K찰국 회장 노조 통합협상   \n",
       "2     ynat-v1_train_00002       2          김정은, 북미 대화 정면돌파 필요하나?   \n",
       "3     ynat-v1_train_00004       6     미대선 앞두고 R2프랑스 단 발 비해 감시 강화   \n",
       "4     ynat-v1_train_00006       1           프로야구 롯데 KIA 광주 경기 취소   \n",
       "...                   ...     ...                            ...   \n",
       "1582  ynat-v1_train_02787       6      13일 노바 라이2·미군 합동演習 이루어진다.   \n",
       "1583  ynat-v1_train_02788       0                     남원소식춘향단 모집   \n",
       "1584  ynat-v1_train_02789       2          이총리, 국회 직 무기대상책 추진해야    \n",
       "1585  ynat-v1_train_02792       1    높`X#E율…}BO Q\"[/선수 몸값 상승 CAO   \n",
       "1586  ynat-v1_train_02797       4  텔레그램+한D 등 업계 2시간  업데이트…39종!2보   \n",
       "\n",
       "     restoration_method  \n",
       "0                    복원  \n",
       "1                    복원  \n",
       "2                    복원  \n",
       "3                    복원  \n",
       "4                    복원  \n",
       "...                 ...  \n",
       "1582                 복원  \n",
       "1583                 복원  \n",
       "1584                 복원  \n",
       "1585              error  \n",
       "1586                 복원  \n",
       "\n",
       "[1587 rows x 4 columns]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restored_df = restored_df.drop(columns=['text'])\n",
    "restored_df = restored_df.rename(columns={'re_text': 'text'})\n",
    "restored_df['target'] = restored_df['target'].map(target_to_domain)\n",
    "restored_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "restored_df = restored_df[restored_df['restoration_method']!='error']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "      <th>ID</th>\n",
       "      <th>restoration_method</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'나의 아티스트, 나만의 색깔'  서울 시립 미술관 신규 전시 기대감 UP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>여름 맞이 '냉면 vs 비빔밥' 맛집 대결 당신은 어떤 선택</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>'스타일 변신', 패션 트렌드 집중 분석  2023년 여름 인기 소품 대방출</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'인생영화, 다시 한번' 오리지널 OST 반복 감상 이유</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>독서 습관 형성 새롭게 출간된 베스트셀러 도서 추천 목록</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2390</th>\n",
       "      <td>3</td>\n",
       "      <td>텅 빈 교실 선생님 외롭게</td>\n",
       "      <td>ynat-v1_train_02786</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2391</th>\n",
       "      <td>6</td>\n",
       "      <td>13일 노바 라이2·미군 합동演習 이루어진다.</td>\n",
       "      <td>ynat-v1_train_02787</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>0</td>\n",
       "      <td>남원소식춘향단 모집</td>\n",
       "      <td>ynat-v1_train_02788</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2393</th>\n",
       "      <td>2</td>\n",
       "      <td>이총리, 국회 직 무기대상책 추진해야</td>\n",
       "      <td>ynat-v1_train_02789</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>4</td>\n",
       "      <td>텔레그램+한D 등 업계 2시간  업데이트…39종!2보</td>\n",
       "      <td>ynat-v1_train_02797</td>\n",
       "      <td>복원</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2395 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      target                                        text                   ID  \\\n",
       "0          0   '나의 아티스트, 나만의 색깔'  서울 시립 미술관 신규 전시 기대감 UP                  NaN   \n",
       "1          0           여름 맞이 '냉면 vs 비빔밥' 맛집 대결 당신은 어떤 선택                  NaN   \n",
       "2          0  '스타일 변신', 패션 트렌드 집중 분석  2023년 여름 인기 소품 대방출                  NaN   \n",
       "3          0             '인생영화, 다시 한번' 오리지널 OST 반복 감상 이유                  NaN   \n",
       "4          0             독서 습관 형성 새롭게 출간된 베스트셀러 도서 추천 목록                  NaN   \n",
       "...      ...                                         ...                  ...   \n",
       "2390       3                              텅 빈 교실 선생님 외롭게  ynat-v1_train_02786   \n",
       "2391       6                   13일 노바 라이2·미군 합동演習 이루어진다.  ynat-v1_train_02787   \n",
       "2392       0                                  남원소식춘향단 모집  ynat-v1_train_02788   \n",
       "2393       2                       이총리, 국회 직 무기대상책 추진해야   ynat-v1_train_02789   \n",
       "2394       4               텔레그램+한D 등 업계 2시간  업데이트…39종!2보  ynat-v1_train_02797   \n",
       "\n",
       "     restoration_method  \n",
       "0                   NaN  \n",
       "1                   NaN  \n",
       "2                   NaN  \n",
       "3                   NaN  \n",
       "4                   NaN  \n",
       "...                 ...  \n",
       "2390                 복원  \n",
       "2391                 복원  \n",
       "2392                 복원  \n",
       "2393                 복원  \n",
       "2394                 복원  \n",
       "\n",
       "[2395 rows x 4 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemma_made = pd.concat([df, restored_df], ignore_index=True)\n",
    "gemma_made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemma_made.to_csv('gemma_made.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
